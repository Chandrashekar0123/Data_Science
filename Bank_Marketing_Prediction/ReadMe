# Bank Marketing Predictions

## Overview

This project aims to build a Decision Tree classifier that predicts whether a customer will purchase a product or service based on demographic and behavioral data. Using the Bank Marketing dataset from the UCI Machine Learning Repository, the project involves data preprocessing (handling missing values, encoding categorical variables), splitting the data into training and testing sets, and training multiple models. The performance of the models is evaluated using accuracy, precision, recall, F1-score, and the confusion matrix. In addition, the Decision Tree is visualized to understand its decision-making process, and optional hyperparameter tuning is applied to improve model performance.

## Table of Contents

- [Dataset](#dataset)
- [Project Structure](#project-structure)
- [Technologies Used](#technologies-used)
- [Data Preprocessing](#data-preprocessing)
- [Exploratory Data Analysis (EDA)](#exploratory-data-analysis-eda)
- [Model Building & Evaluation](#model-building--evaluation)
  - [Logistic Regression](#logistic-regression)
  - [K-Nearest Neighbors (KNN)](#k-nearest-neighbors-knn)
  - [Decision Tree Classifier](#decision-tree-classifier)
- [Decision Tree Visualization](#decision-tree-visualization)
- [Results Summary](#results-summary)


## Dataset

The Bank Marketing dataset is sourced from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/222/bank+marketing). It contains customer information such as age, job, marital status, education, balance, housing, loan, contact type, and more. The target variable indicates whether a customer subscribed to a product/service.

## Project Structure

The repository is organized as follows:

- **data/**: Contains the raw dataset (e.g., `bank-full.csv`).
- **notebooks/**: Jupyter notebooks for data exploration, visualization, and model experiments.
- **src/**: Python scripts for data preprocessing, model building, and evaluation.
- **outputs/**: Saved plots and model artifacts (e.g., Decision Tree visualizations).
- **requirements.txt**: List of project dependencies.
- **README.md**: Project documentation.

## Technologies Used

- **Python** for data analysis and modeling.
- **pandas** and **NumPy** for data manipulation.
- **matplotlib** and **seaborn** for visualization.
- **scikit-learn** for building and evaluating machine learning models.
- **imblearn** for handling class imbalance (SMOTE).

## Data Preprocessing

Key preprocessing steps include:

- **Loading the Dataset**: Reading the CSV file with appropriate delimiters and quoting.
- **Data Exploration**: Inspecting data shape, missing values, and column names.
- **Categorical Encoding**: Converting categorical features (e.g., job, marital status, education, contact, month, etc.) to numerical values.
- **Handling Missing Values**: Imputing missing values where necessary.
- **Feature Selection**: Removing features with low correlation to the target variable.
- **Balancing the Dataset**: Using SMOTE to balance the class labels for the training set.

## Exploratory Data Analysis (EDA)

EDA was performed to understand the distribution of features and the target variable. This involved:

- Visualizing distributions of categorical features using count plots.
- Creating a correlation heatmap to identify relationships among variables.
- Analyzing the distribution of the target variable to detect class imbalance.

## Model Building & Evaluation

The project explores multiple classification models to predict customer subscription:

### Logistic Regression

A Logistic Regression model was built and evaluated. The modelâ€™s performance was measured using standard metrics, including accuracy, precision, recall, and F1-score. The evaluation indicated competitive performance, with high accuracy but challenges in predicting the minority class.

### K-Nearest Neighbors (KNN)

A KNN classifier was implemented and its performance was assessed. Although it provided similar overall accuracy to Logistic Regression, its precision and recall for the minority class were lower.

### Decision Tree Classifier

A Decision Tree model was trained with hyperparameter tuning (e.g., using the Gini criterion, controlled depth, and minimum samples per leaf). This model not only achieved a slightly higher overall accuracy but also offered clear interpretability through its decision rules.

## Decision Tree Visualization

The Decision Tree classifier was visualized to provide insights into its decision-making process. The tree diagram (with a limited depth for clarity) illustrates how features such as housing status, contact type, month, call duration, and previous outcomes contribute to the prediction. A textual representation of the tree is also provided for further interpretability.

## Results Summary

| **Model**              | **Accuracy** | **Precision (Class 1)** | **Recall (Class 1)** | **F1-score (Class 1)** |
|------------------------|--------------|-------------------------|----------------------|------------------------|
| **Logistic Regression**| 0.89         | 0.62                    | 0.29                 | 0.40                   |
| **K-Nearest Neighbors**| 0.88         | 0.52                    | 0.37                 | 0.43                   |
| **Decision Tree**      | 0.90         | 0.61                    | 0.40                 | 0.48                   |

*Note: Although all models show competitive accuracy, the Decision Tree classifier offers additional interpretability through visualization of decision rules.*




